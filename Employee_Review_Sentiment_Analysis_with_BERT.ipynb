{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Employee_Review_Sentiment_Analysis_with_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73a566f2f61c41b799655d0bd583c38d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7c595cae22184fedb0b8411d671b7f18",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_38e545c0519f45aeb3e7a989dd1202c2",
              "IPY_MODEL_30f0b3d0366a4e2ca6f5995841c4f54b"
            ]
          }
        },
        "7c595cae22184fedb0b8411d671b7f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38e545c0519f45aeb3e7a989dd1202c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1cf32a510c424b13b9179e7d64d0c1a2",
            "_dom_classes": [],
            "description": "  7%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 15,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a97702329d1445449cbc4370c95f574a"
          }
        },
        "30f0b3d0366a4e2ca6f5995841c4f54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7711c871c306468f995d7ebbbbcb5dc5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/15 [03:00&lt;40:19, 172.85s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b15e1668f672426ba2e6a466118fbd49"
          }
        },
        "1cf32a510c424b13b9179e7d64d0c1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a97702329d1445449cbc4370c95f574a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7711c871c306468f995d7ebbbbcb5dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b15e1668f672426ba2e6a466118fbd49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "507a517973a14e4299050f9851cb358d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6153b03fef904fe5800ebc0c53ac9e46",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_221176bac99949fa83ba11d2fcd0041c",
              "IPY_MODEL_cde52c42200740e7b4cc1e01174db9df"
            ]
          }
        },
        "6153b03fef904fe5800ebc0c53ac9e46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "221176bac99949fa83ba11d2fcd0041c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_80cfcebca2a84c05b02df24fa8b930bf",
            "_dom_classes": [],
            "description": "Epoch 1: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 171,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 171,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc2187b529c84e9dae2f0c1a9fe9a04d"
          }
        },
        "cde52c42200740e7b4cc1e01174db9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_48de11e0031f49399b4845d87de4d6e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 171/171 [02:44&lt;00:00,  1.04it/s, training_loss=0.574]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_516338bee1ca487f91806f69fd07e8db"
          }
        },
        "80cfcebca2a84c05b02df24fa8b930bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc2187b529c84e9dae2f0c1a9fe9a04d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48de11e0031f49399b4845d87de4d6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "516338bee1ca487f91806f69fd07e8db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "020a43b1fa3c4d519384cd3303583408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fc47cd0a6ae741eeb378c0fa05d4b34d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed26e85c43714a3b8e940b72eaebe140",
              "IPY_MODEL_ec35b4f17712419a8892cc9b7d6b1f4c"
            ]
          }
        },
        "fc47cd0a6ae741eeb378c0fa05d4b34d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed26e85c43714a3b8e940b72eaebe140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4810169acf244c1d939c52f11e36dadf",
            "_dom_classes": [],
            "description": "Epoch 2:   5%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 171,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a187990361eb490689a3d4c252d68b54"
          }
        },
        "ec35b4f17712419a8892cc9b7d6b1f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5884e98c9d8e4e688150c5b11edb1727",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8/171 [00:07&lt;02:36,  1.04it/s, training_loss=0.650]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c7e751fcb7342c2b51969d54aa40cf1"
          }
        },
        "4810169acf244c1d939c52f11e36dadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a187990361eb490689a3d4c252d68b54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5884e98c9d8e4e688150c5b11edb1727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c7e751fcb7342c2b51969d54aa40cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "Iwit3oicQ84N"
      },
      "source": [
        "# Employee Review Sentiment Analysis with BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aDXyB3LKwx0"
      },
      "source": [
        "__author__ = \"Fiodar Ryzhykau\"\n",
        "__version__ = \"CS224u, Stanford, Fall 2020\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "Wtq8_i66Q84Q"
      },
      "source": [
        "### Project Outline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "true",
        "id": "zI6dPJVRQ84R"
      },
      "source": [
        "**Step 1**: Project Introduction\n",
        "\n",
        "**Step 2**: Exploratory Data Analysis and Preprocessing\n",
        "\n",
        "**Step 3**: Training/Validation Split\n",
        "\n",
        "**Step 4**: Loading Tokenizer and Encoding the Data\n",
        "\n",
        "**Step 5**: Setting up BERT Pretrained Model\n",
        "\n",
        "**Step 6**: Creating Data Loaders\n",
        "\n",
        "**Step 7**: Setting Up Optimizer and Scheduler\n",
        "\n",
        "**Step 8**: Defining the Performance Metrics\n",
        "\n",
        "**Step 9**: Training the Model\n",
        "\n",
        "**Step 10**: Result Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "JZMBPgb1Q84T"
      },
      "source": [
        "## Step 1: Project Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "true",
        "id": "nzNaxJHwQ84U"
      },
      "source": [
        "\n",
        "For my Final Project in the Stanford NLU course I’ve selected a topic that is related to the employee assessment in modern companies. In my current company, every quarter (and annually) managers should provide feedback to their team-members and grade their Performance and Potential in order to objectify the value of that employee to the company. \n",
        "\n",
        "We use the “9-box model”, which is also called the “Performance and Potential Model” and has been developed by McKinsey. This approach is used in many companies as a method to identify, support and promote the talent. \n",
        "\n",
        " \n",
        "Feedback (review) that is being submitted along the 9-box grade should explicitly describe all the strong and weak points of the employee, as well as sentiment to the contribution and progress for the given quarter. Submitted data basically represents a mapping/summarization of the feedback to one of the 9 categories.\n",
        "\n",
        "\n",
        "Models used:\n",
        "* [HuggingFace models](https://huggingface.co/transformers/model_doc/bert.html)\n",
        "\n",
        "* [Bert overview](https://characters.fandom.com/wiki/Bert_(Sesame_Street). \n",
        "For more information, the original paper can be found [here](https://arxiv.org/abs/1810.04805). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "yMkHD0dbQ84X"
      },
      "source": [
        "## Step 2: Exploratory Data Analysis and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHe5dM5jsZF5"
      },
      "source": [
        "Dataset Has been collected from Amazon MTurk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rZ6in81diJD",
        "outputId": "46dc7276-a00d-49ab-c026-93c77bc6d586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "XwRRazzMQ84Y"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "om0t0Q07Q84c"
      },
      "source": [
        "pd.set_option('display.max_colwidth', 2000)\n",
        "df = pd.read_csv('drive/My Drive/Collab_Drive/employee_review_mturk_dataset_13_and_test_v2.csv')\n",
        "df.set_index('id', inplace=True)\n",
        "df.dropna(inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "V49dybGbQ84i",
        "outputId": "53b6b109-1297-406f-c697-e8b28870c9f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "source": [
        "df.head(3)\n",
        "#df.tail(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_name</th>\n",
              "      <th>nine_box_category</th>\n",
              "      <th>feedback</th>\n",
              "      <th>performance_class</th>\n",
              "      <th>potential_class</th>\n",
              "      <th>adjusted</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>John Doe</td>\n",
              "      <td>Category 1: 'Risk' (Low performance, Low potential)</td>\n",
              "      <td>John has not progressed in his position. He is continuously late, leaves early, and takes many breaks throughout the day. He calls out at least every other week and it's always on Fridays. His performance has significantly declined. My suggestion is he is not suitable for this position.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>John Doe</td>\n",
              "      <td>Category 1: 'Risk' (Low performance, Low potential)</td>\n",
              "      <td>John has consistently disappointed me this quarter with his shoddy work product. I asked him for a report and gave him a lenient two-week deadline, but he blew past that deadline without even informing me. When he finally turned the report in, it was three weeks late and riddled with typos. He did not seem interested in any of the comments that I made on that report, even though I made them for his benefit so he would understand what a high-quality report is supposed to look like.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>John Doe</td>\n",
              "      <td>Category 1: 'Risk' (Low performance, Low potential)</td>\n",
              "      <td>John turned in subpar work product all quarter. When I asked him to make revisions, he repeatedly failed to implement the corrections that I had requested. He also seemed confused and lost whenever we had discussions about the reports and the numbers in the data. He was not interested in learning more when I gave him opportunities to participate in trainings. He seems to have already reached his full potential here, which is disappointing given the quality of work I've seen from him.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   person_name  ... adjusted\n",
              "id              ...         \n",
              "1     John Doe  ...    False\n",
              "2     John Doe  ...    False\n",
              "3     John Doe  ...    False\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "ppUJ5lp4Q844"
      },
      "source": [
        "possible_labels = df.nine_box_category.unique()\n",
        "possible_labels = np.sort(possible_labels)\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "\n",
        "label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "pp_map = {}\n",
        "pp_map[0] = [0,0]\n",
        "pp_map[1] = [1,0]\n",
        "pp_map[2] = [2,0]\n",
        "pp_map[3] = [0,1]\n",
        "pp_map[4] = [1,1]\n",
        "pp_map[5] = [2,1]\n",
        "pp_map[6] = [0,2]\n",
        "pp_map[7] = [1,2]\n",
        "pp_map[8] = [2,2]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RDHgp18Xllr",
        "outputId": "c349204f-b4c2-419a-fe0f-d3c86a09c76c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import nltk.data\n",
        "from nltk import tokenize\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8OIFNPjvmMM",
        "outputId": "bcdebea4-b667-40dd-cdf5-42312cb1d670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "source": [
        "print(f'\\nInitial dataset size: {len(df.index)}')\n",
        "\n",
        "df_upd = df.copy()\n",
        "df_upd['label'] = df_upd.nine_box_category.replace(label_dict)\n",
        "df_upd['feedback'] = df_upd.feedback.replace('\\\\r',' ', regex=True)\n",
        "df_upd['feedback_len'] = df_upd.feedback.str.len()\n",
        "df_upd['num_of_sent'] = df_upd.feedback.apply(lambda s: len(tokenize.sent_tokenize(s)))\n",
        "df_upd['performance_class'] = df_upd.label.apply(lambda l: pp_map[l][0])\n",
        "df_upd['potential_class'] = df_upd.label.apply(lambda l: pp_map[l][1])\n",
        "\n",
        "feedback_len_stats = df_upd['feedback_len'].describe(percentiles=[.05,.10,.25,.50,.75,.85,.90,.95])\n",
        "print(f'\\nFeedback len stats: \\n{feedback_len_stats}')\n",
        "\n",
        "num_of_sent_stats = df_upd['num_of_sent'].describe(percentiles=[.05,.10,.25,.50,.75,.85,.90,.95])\n",
        "print(f'\\nFeedback sentence num stats: \\n{num_of_sent_stats}')\n",
        "\n",
        "df_upd = df_upd.loc[(df_upd['feedback_len'] > 150) & (df_upd['feedback_len'] < 600)]\n",
        "df_upd = df_upd.loc[df_upd['num_of_sent'] > 1]\n",
        "df_upd = df_upd.loc[~df_upd['feedback'].str.contains('category') & ~df_upd['feedback'].str.contains('Category')]\n",
        "\n",
        "print(f'\\nSize after filtering: {len(df_upd.index)}')\n",
        "\n",
        "df = df_upd.sort_values(by=['label']).copy()\n",
        "#df.tail()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Initial dataset size: 926\n",
            "\n",
            "Feedback len stats: \n",
            "count     926.000000\n",
            "mean      332.526998\n",
            "std       137.875082\n",
            "min        59.000000\n",
            "5%        147.000000\n",
            "10%       176.000000\n",
            "25%       237.000000\n",
            "50%       314.000000\n",
            "75%       405.000000\n",
            "85%       481.250000\n",
            "90%       523.000000\n",
            "95%       580.750000\n",
            "max      1060.000000\n",
            "Name: feedback_len, dtype: float64\n",
            "\n",
            "Feedback sentence num stats: \n",
            "count    926.000000\n",
            "mean       4.139309\n",
            "std        1.238582\n",
            "min        1.000000\n",
            "5%         2.000000\n",
            "10%        3.000000\n",
            "25%        4.000000\n",
            "50%        4.000000\n",
            "75%        5.000000\n",
            "85%        5.000000\n",
            "90%        5.000000\n",
            "95%        6.000000\n",
            "max       24.000000\n",
            "Name: num_of_sent, dtype: float64\n",
            "\n",
            "Size after filtering: 805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k7J7FxZoguI",
        "outputId": "9e98e8a2-a212-49a4-9e7a-76ce13a97ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "#bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "res = df_upd['feedback_len'].value_counts(bins=10, sort=False)\n",
        "print(f'\\nDistribution by len in filtered: \\n{res}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Distribution by len in filtered: \n",
            "(150.553, 195.6]     72\n",
            "(195.6, 240.2]      101\n",
            "(240.2, 284.8]      136\n",
            "(284.8, 329.4]      128\n",
            "(329.4, 374.0]      106\n",
            "(374.0, 418.6]       90\n",
            "(418.6, 463.2]       55\n",
            "(463.2, 507.8]       48\n",
            "(507.8, 552.4]       39\n",
            "(552.4, 597.0]       30\n",
            "Name: feedback_len, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "AWM7RxyEQ84p",
        "outputId": "7ff61693-3767-4d31-d169-d09523b967a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "df.performance_class.value_counts().sort_index()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    273\n",
              "1    260\n",
              "2    272\n",
              "Name: performance_class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWvm-EqirGN2",
        "outputId": "c16722f6-64bf-4600-afc5-c70307f02dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "df.potential_class.value_counts().sort_index()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    292\n",
              "1    264\n",
              "2    249\n",
              "Name: potential_class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZkrGWDerj_Y",
        "outputId": "687f73f3-7096-417c-a466-48ce6aa72eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "df.nine_box_category.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Category 3: 'Solid Performer' (High performance, Low potential)            102\n",
              "Category 1: 'Risk' (Low performance, Low potential)                        102\n",
              "Category 5: 'Core Player' (Moderate performance, Moderate potential)        95\n",
              "Category 9: 'Star' (High performance, High potential)                       92\n",
              "Category 4: 'Inconsistent Player' (Low performance, Moderate potential)     91\n",
              "Category 2: 'Average performer' (Moderate performance, Low potential)       88\n",
              "Category 7: 'Potential Gem' (Low performance, High potential)               80\n",
              "Category 6: 'High Performer' (High performance, Moderate potential)         78\n",
              "Category 8: 'High Potential' (Moderate performance, High potential)         77\n",
              "Name: nine_box_category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "x0xErI_4Q85E"
      },
      "source": [
        "## Step 3: Training/Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "GIdvXctMQ85F"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "Q8r9-waxQ85J"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
        "                                                  df.label.values, \n",
        "                                                  test_size=0.15, \n",
        "                                                  random_state=17, \n",
        "                                                  stratify=df.label.values)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "Rxa7gcDSQ85O"
      },
      "source": [
        "df['data_type'] = ['not_set']*df.shape[0]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "8S_ZlXPeQ85Q"
      },
      "source": [
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "C7brvTjQQ85T"
      },
      "source": [
        "df.groupby(['nine_box_category', 'label', 'data_type']).count()\n",
        "pass"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "qtdohahAQ85X"
      },
      "source": [
        "## Step 4: Loading Tokenizer and Encoding the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-wd4Jc-SgF-",
        "outputId": "ece8a2b9-1258-40fe-8f9a-83f026b33d10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "!pip install transformers\n",
        "pass"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "rKaxlEJxQ85X"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "ynjt25pGQ85a"
      },
      "source": [
        "#bert_type = 'bert-base-cased'\n",
        "bert_type = 'bert-large-uncased'\n",
        "convert_to_lowercase=True\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_type, \n",
        "                                          do_lower_case=convert_to_lowercase)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "cCTqwNQSQ85c"
      },
      "source": [
        "tensor_size=512\n",
        "\n",
        "train_df = df[df.data_type=='train']\n",
        "\n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    train_df.feedback.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    padding='max_length', \n",
        "    max_length=tensor_size, \n",
        "    return_tensors='pt',\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "val_df = df[df.data_type=='val']\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    val_df.feedback.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    padding='max_length', \n",
        "    max_length=tensor_size, \n",
        "    return_tensors='pt',\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(train_df.label.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(val_df.label.values)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WilOau4I5fH"
      },
      "source": [
        "train_df.to_csv('train_set.csv')\n",
        "val_df.to_csv('validation_set.csv')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "KDOiiW9KQ85f"
      },
      "source": [
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "g420XXkIQ85h",
        "outputId": "c259533f-7975-48c2-c57e-446ea5fe28cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(f'Dataset size full     : {len(dataset_train) + len(dataset_val)}')\n",
        "print(f'Dataset for training  : {len(dataset_train)}')\n",
        "print(f'Dataset for validation: {len(dataset_val)}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset size full     : 805\n",
            "Dataset for training  : 684\n",
            "Dataset for validation: 121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "mdV9g48-Q85r"
      },
      "source": [
        "## Step 5: Setting up BERT Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "7V_44GZeQ85t"
      },
      "source": [
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "EZsdOfpKQ85y",
        "outputId": "92f97e51-0ec9-4395-9a89-1247fa384b42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "print(f'Num of labels:{len(label_dict)}')\n",
        "model = BertForSequenceClassification.from_pretrained(bert_type,\n",
        "                                                      num_labels=len(label_dict),\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of labels:9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "p1iboKn1Q855"
      },
      "source": [
        "## Step 6: Creating Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "uR-oT3FsQ855"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "IzBHPc4mQ858"
      },
      "source": [
        "batch_size = 4 #large_bert\n",
        "#batch_size = 16 #base_bert\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, \n",
        "                              sampler=RandomSampler(dataset_train), \n",
        "                              batch_size=batch_size)\n",
        "\n",
        "dataloader_validation = DataLoader(dataset_val, \n",
        "                                   sampler=SequentialSampler(dataset_val), \n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "B15gaVtpQ85_"
      },
      "source": [
        "## Step 7: Setting Up Optimiser and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "ITops_-XQ86A"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "RdRh35-rQ86C"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=1e-5, \n",
        "                  eps=1e-8)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "r21WyV36Q86H"
      },
      "source": [
        "#epochs = 40 #base_bert\n",
        "epochs = 15 #large_bert\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(dataloader_train)*epochs)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "cPISNRn9Q86J"
      },
      "source": [
        "## Step 8:Defining the Performance Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "caySsoktQ86K"
      },
      "source": [
        "Accuracy metric approach originally used in accuracy function in [this tutorial](https://mccormickml.com/2019/07/22/BERT-fine-tuning/#41-bertforsequenceclassification)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "pu6Oq2v2Q86N"
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "CeGH38vLQ86Q"
      },
      "source": [
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHeMCPj3VdeB"
      },
      "source": [
        "def get_dataset_id_label_map(input_df):\n",
        "    labels = input_df.label.unique()\n",
        "    #print(labels)\n",
        "    result_map = dict()\n",
        "    for label in labels:\n",
        "        rows_with_labels = input_df.loc[input_df['label'] == label]\n",
        "        ids = rows_with_labels.index\n",
        "        #print(f'Label {label} ids: {ids}')\n",
        "        result_map[label] = ids.copy()\n",
        "    return result_map\n",
        "\n",
        "#print(get_dataset_id_label_map(test_df))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "rkV2chWQQ86T"
      },
      "source": [
        "def calculate_stats_per_class(preds, labels, input_df=pd.DataFrame()):\n",
        "\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    total_correct = 0\n",
        "    overall_gold = 0\n",
        "    id_map = get_dataset_id_label_map(input_df)   \n",
        "    output_df  = input_df.copy()    \n",
        "    all_predictions = np.array([])\n",
        "    \n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]  \n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "\n",
        "        all_predictions = np.concatenate((all_predictions, y_preds), axis=0)\n",
        "\n",
        "        correct = len(y_preds[y_preds==label])\n",
        "        total_correct += correct\n",
        "        num_of_gold = len(y_true)\n",
        "        overall_gold += num_of_gold\n",
        "\n",
        "        print(f'Predictions: {y_preds}')\n",
        "        print(f'Gold Values: {y_true}')\n",
        "        print(f'Ids: {id_map[label]}')\n",
        "       \n",
        "        print(f'Accuracy: {correct} / {num_of_gold}\\n')  \n",
        "\n",
        "    print(f'Total Correct/Gold: {total_correct}/{overall_gold}\\n')\n",
        "    print(f'AVG Accuracy: {total_correct / overall_gold}\\n')\n",
        "\n",
        "    output_df['ml_prediction_label'] = pd.Series(all_predictions, index=output_df.index)\n",
        "    output_df['ml_category'] = output_df.ml_prediction_label.apply(lambda l: label_dict_inverse[l])\n",
        "    output_df['ml_performance_class'] = output_df.ml_prediction_label.apply(lambda l: pp_map[l][0])\n",
        "    output_df['ml_potential_class'] = output_df.ml_prediction_label.apply(lambda l: pp_map[l][1])\n",
        "    output_df['ml_match'] = output_df.apply(lambda row: row.label == row.ml_prediction_label, axis=1)\n",
        "    output_df['performance_match'] = output_df.apply(lambda row: row.performance_class == row.ml_performance_class, axis=1)\n",
        "    output_df['potential_match'] = output_df.apply(lambda row: row.potential_class == row.ml_potential_class, axis=1)\n",
        "    \n",
        "    return output_df"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "YUfDWA0AQ86X"
      },
      "source": [
        "## Step 9: Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "Ui53HE_7Q86Y"
      },
      "source": [
        "Approach adapted from an older version of HuggingFace's `run_glue.py` script. Accessible [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "TWi7QO6-Q86Z"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "82MhU1tmQ86b",
        "outputId": "c945bc60-d598-4b2d-b815-c4f2a7a88d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "if not os.path.exists('trained_models'):\n",
        "    os.makedirs('trained_models')\n",
        "if not os.path.exists('stats'):\n",
        "    os.makedirs('stats')\n",
        "if not os.path.exists('analysis'):\n",
        "    os.makedirs('analysis')\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "gEU-EtrIQ86e"
      },
      "source": [
        "def evaluate(dataloader_values, target_model):\n",
        "\n",
        "    target_model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in dataloader_values:\n",
        "        #print(f'batch {batch.size()}')\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "        #print(f'input_ids: {batch[0]}')\n",
        "        #print(f'labels: {batch[2]}')\n",
        "        with torch.no_grad():        \n",
        "            outputs = target_model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        #print(f'logits {logits}')\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_values) \n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "-r9pn-gpQ86g",
        "outputId": "53502269-fb81-434d-dbe3-4354dcbdcd4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537,
          "referenced_widgets": [
            "73a566f2f61c41b799655d0bd583c38d",
            "7c595cae22184fedb0b8411d671b7f18",
            "38e545c0519f45aeb3e7a989dd1202c2",
            "30f0b3d0366a4e2ca6f5995841c4f54b",
            "1cf32a510c424b13b9179e7d64d0c1a2",
            "a97702329d1445449cbc4370c95f574a",
            "7711c871c306468f995d7ebbbbcb5dc5",
            "b15e1668f672426ba2e6a466118fbd49",
            "507a517973a14e4299050f9851cb358d",
            "6153b03fef904fe5800ebc0c53ac9e46",
            "221176bac99949fa83ba11d2fcd0041c",
            "cde52c42200740e7b4cc1e01174db9df",
            "80cfcebca2a84c05b02df24fa8b930bf",
            "cc2187b529c84e9dae2f0c1a9fe9a04d",
            "48de11e0031f49399b4845d87de4d6e0",
            "516338bee1ca487f91806f69fd07e8db",
            "020a43b1fa3c4d519384cd3303583408",
            "fc47cd0a6ae741eeb378c0fa05d4b34d",
            "ed26e85c43714a3b8e940b72eaebe140",
            "ec35b4f17712419a8892cc9b7d6b1f4c",
            "4810169acf244c1d939c52f11e36dadf",
            "a187990361eb490689a3d4c252d68b54",
            "5884e98c9d8e4e688150c5b11edb1727",
            "8c7e751fcb7342c2b51969d54aa40cf1"
          ]
        }
      },
      "source": [
        "epoch_list = []\n",
        "train_loss = []\n",
        "validation_loss = []\n",
        "f1_scores_weighted = []\n",
        "#min_epoch_to_save = 30 #base_bert\n",
        "min_epoch_to_save = 5 #large_bert\n",
        "\n",
        "\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        model.zero_grad()\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        #print(f'batch[0] - input_ids: {batch[0].size()}' )\n",
        "        #print(f'batch[1] - attention_mask: {batch[1].size()}' )\n",
        "        #print(f'batch[2] - labels: {batch[2].size()}' )\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }       \n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        #print(f'loss {loss}')\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "         \n",
        "        \n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)             \n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_validation, model)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
        "\n",
        "    epoch_list.append(epoch)\n",
        "    train_loss.append(loss_train_avg)\n",
        "    validation_loss.append(val_loss)\n",
        "    f1_scores_weighted.append(val_f1)\n",
        "\n",
        "    if (epoch > min_epoch_to_save):    \n",
        "        torch.save(model.state_dict(), f'trained_models/finetuned_BERT_epoch_{epoch}.model')\n",
        "\n",
        "        df_learning_curve = pd.DataFrame({'epoch': epoch_list,\n",
        "                      'train_loss_avg': train_loss,\n",
        "                      'validation_loss': validation_loss,\n",
        "                      'val_f1_weighted': f1_scores_weighted})\n",
        "\n",
        "        lc_file_name = f'stats/learning_curve_{epoch}.csv'\n",
        "        df_learning_curve.to_csv(lc_file_name, index=False)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73a566f2f61c41b799655d0bd583c38d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "507a517973a14e4299050f9851cb358d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=171.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Epoch 1\n",
            "Training loss: 2.0875775486405135\n",
            "Validation loss: 1.750309040469508\n",
            "F1 Score (Weighted): 0.3030180704551322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "020a43b1fa3c4d519384cd3303583408",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=171.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e11f032b2b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                  }       \n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m         )\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m                 )\n\u001b[1;32m    484\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         )\n\u001b[1;32m    404\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         )\n\u001b[1;32m    341\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "p_ZOcJ8p3NgF"
      },
      "source": [
        "## Step 10: Result Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZfd894GFu17"
      },
      "source": [
        "#Preparing Test Set\n",
        "test_df = pd.read_csv(f'drive/My Drive/Collab_Drive/employee_review_mturk_dataset_test_batch_2_v1.csv')\n",
        "val_r = test_df.loc[test_df['id'] == 20086].feedback\n",
        "#print(val_r)\n",
        "#print(val_r.str.replace(r'\\r',' '))\n",
        "\n",
        "test_df.set_index('id', inplace=True)\n",
        "test_df.dropna(inplace=True)\n",
        "\n",
        "test_df['feedback'] = test_df.feedback.replace('\\\\r',' ', regex=True)\n",
        "test_df['label'] = test_df.nine_box_category.replace(label_dict)\n",
        "test_df = test_df.sort_values(by=['label'])\n",
        "test_df.to_csv(f'test_set.csv')\n",
        "#test_df.head()\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E0nuVwJ7h1H",
        "outputId": "0da504c3-c723-4363-a357-b656346ce6ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "print(f'Test Set size: {len(test_df)}')\n",
        "print(f'Num of Test Classes: {test_df.nine_box_category.value_counts()}')\n",
        "\n",
        "tensor_size=512\n",
        "\n",
        "encoded_data_test = tokenizer.batch_encode_plus(\n",
        "    test_df.feedback.values, \n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True, \n",
        "    padding='max_length', \n",
        "    max_length=tensor_size, \n",
        "    return_tensors='pt',\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "\n",
        "input_ids_test = encoded_data_test['input_ids']\n",
        "attention_masks_test = encoded_data_test['attention_mask']\n",
        "labels_test = torch.tensor(test_df.label.values)\n",
        "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "\n",
        "dataloader_test = DataLoader(dataset_test, \n",
        "                                   sampler=SequentialSampler(dataset_test), \n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Set size: 233\n",
            "Num of Test Classes: Category 5: 'Core Player' (Moderate performance, Moderate potential)       30\n",
            "Category 2: 'Average performer' (Moderate performance, Low potential)      28\n",
            "Category 3: 'Solid Performer' (High performance, Low potential)            27\n",
            "Category 1: 'Risk' (Low performance, Low potential)                        27\n",
            "Category 4: 'Inconsistent Player' (Low performance, Moderate potential)    26\n",
            "Category 8: 'High Potential' (Moderate performance, High potential)        25\n",
            "Category 9: 'Star' (High performance, High potential)                      24\n",
            "Category 6: 'High Performer' (High performance, Moderate potential)        24\n",
            "Category 7: 'Potential Gem' (Low performance, High potential)              22\n",
            "Name: nine_box_category, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "TNBUcHHdQ86m",
        "outputId": "3f3f6450-6286-4665-b9de-a66e23413a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "#print(f'Num of classes {len(label_dict)}')\n",
        "eval_model = BertForSequenceClassification.from_pretrained(bert_type,\n",
        "                                                      num_labels=len(label_dict),\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "\n",
        "eval_model.to(device)\n",
        "pass"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "Mtt1K_9GQ86r",
        "outputId": "cecd2a59-7baa-4259-ab74-74fa2254667e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#eval_model_path = f'drive/My Drive/Collab_Drive/v3.1/finetuned_BERT_epoch_50.model'\n",
        "eval_model_path = f'trained_models/finetuned_BERT_epoch_15.model'\n",
        "#eval_model_path = f'trained_models/finetuned_BERT_epoch_{epochs}.model'\n",
        "eval_model.load_state_dict(torch.load(eval_model_path, map_location=torch.device('cpu')))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "oa5rjs2zQ86u",
        "outputId": "40421dfa-2046-4590-8ec7-faad954d0ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "_, val_predictions, true_val_vals = evaluate(dataloader_validation, eval_model)\n",
        "output_val_df = calculate_stats_per_class(val_predictions, true_val_vals, val_df)\n",
        "output_val_df.to_csv('analysis/validation_set_analysis.csv')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: Category 1: 'Risk' (Low performance, Low potential)\n",
            "Predictions: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "Gold Values: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Ids: Int64Index([86, 81, 80, 71, 69, 63, 10209, 10127, 10125, 10085, 10084, 26, 15,\n",
            "            33, 57],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 14 / 15\n",
            "\n",
            "Class: Category 2: 'Average performer' (Moderate performance, Low potential)\n",
            "Predictions: [3 1 1 4 1 2 1 1 1 4 1 1 2]\n",
            "Gold Values: [1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Ids: Int64Index([10089, 10052, 10088, 10090, 128, 111, 141, 146, 129, 106, 153, 152,\n",
            "            130],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 8 / 13\n",
            "\n",
            "Class: Category 3: 'Solid Performer' (High performance, Low potential)\n",
            "Predictions: [2 2 2 5 4 2 1 2 2 2 2 2 2 2 6]\n",
            "Gold Values: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Ids: Int64Index([10220, 10178, 10096, 10134,   240,   224,   209,   227,   251,\n",
            "              250,   231,   191,   205,   254,   256],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 11 / 15\n",
            "\n",
            "Class: Category 4: 'Inconsistent Player' (Low performance, Moderate potential)\n",
            "Predictions: [3 0 0 3 4 3 3 3 3 3 3 3 3 3]\n",
            "Gold Values: [3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
            "Ids: Int64Index([10063, 10059, 10140, 10098, 10222,   296,   308,   265,   284,\n",
            "              312, 10223,   315,   322,   320],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 11 / 14\n",
            "\n",
            "Class: Category 5: 'Core Player' (Moderate performance, Moderate potential)\n",
            "Predictions: [7 2 4 4 5 4 2 4 4 1 2 4 4 4]\n",
            "Gold Values: [4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
            "Ids: Int64Index([10064, 10185, 10146, 10019, 10226, 390, 388, 395, 342, 259, 131,\n",
            "            354, 362, 367],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 8 / 14\n",
            "\n",
            "Class: Category 6: 'High Performer' (High performance, Moderate potential)\n",
            "Predictions: [5 5 5 2 5 2 4 5 2 2 5 2]\n",
            "Gold Values: [5 5 5 5 5 5 5 5 5 5 5 5]\n",
            "Ids: Int64Index([447, 481, 458, 462, 439, 10190, 10151, 421, 431, 429, 10068, 487], dtype='int64', name='id')\n",
            "Accuracy: 6 / 12\n",
            "\n",
            "Class: Category 7: 'Potential Gem' (Low performance, High potential)\n",
            "Predictions: [2 6 6 6 6 2 6 6 2 4 6 6]\n",
            "Gold Values: [6 6 6 6 6 6 6 6 6 6 6 6]\n",
            "Ids: Int64Index([550, 547, 544, 543, 539, 10114, 559, 557, 554, 10154, 495, 493], dtype='int64', name='id')\n",
            "Accuracy: 8 / 12\n",
            "\n",
            "Class: Category 8: 'High Potential' (Moderate performance, High potential)\n",
            "Predictions: [7 7 5 7 5 7 7 4 7 7 7 7]\n",
            "Gold Values: [7 7 7 7 7 7 7 7 7 7 7 7]\n",
            "Ids: Int64Index([575, 585, 586, 10119, 375, 564, 592, 591, 624, 627, 608, 602], dtype='int64', name='id')\n",
            "Accuracy: 9 / 12\n",
            "\n",
            "Class: Category 9: 'Star' (High performance, High potential)\n",
            "Predictions: [8 5 5 8 5 8 8 8 8 8 5 8 2 8]\n",
            "Gold Values: [8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
            "Ids: Int64Index([677, 10081, 664, 692, 663, 646, 10039, 10040, 10124, 700, 694, 706,\n",
            "            707, 10080],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 9 / 14\n",
            "\n",
            "Total Correct/Gold: 84/121\n",
            "\n",
            "AVG Accuracy: 0.6942148760330579\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "ZBAmwmGLQ86y",
        "outputId": "6a529cdd-b71e-43c3-c57c-ce3c5aa950cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "_, test_predictions, true_test_vals = evaluate(dataloader_test, eval_model)\n",
        "output_test_df = calculate_stats_per_class(test_predictions, true_test_vals, test_df)\n",
        "output_test_df.to_csv('analysis/test_set_analysis.csv')\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: Category 1: 'Risk' (Low performance, Low potential)\n",
            "Predictions: [0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 3 0 3]\n",
            "Gold Values: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Ids: Int64Index([20001, 20212, 20043, 20044, 20045, 20046, 20047, 20127, 20173,\n",
            "            20172, 20171, 20170, 20085, 20086, 20087, 20088, 20089, 20130,\n",
            "            20129, 20128, 20213, 20214, 20126, 20005, 20004, 20003, 20002],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 23 / 27\n",
            "\n",
            "Class: Category 2: 'Average performer' (Moderate performance, Low potential)\n",
            "Predictions: [2 5 0 7 2 1 1 1 1 4 4 1 2 1 2 4 1 1 3 1 5 3 1 1 2 1 1 1]\n",
            "Gold Values: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Ids: Int64Index([20176, 20050, 20051, 20090, 20177, 20175, 20174, 20010, 20094,\n",
            "            20093, 20092, 20009, 20008, 20007, 20006, 20049, 20048, 20091,\n",
            "            20133, 20131, 20215, 20135, 20134, 20219, 20218, 20217, 20132,\n",
            "            20216],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 14 / 28\n",
            "\n",
            "Class: Category 3: 'Solid Performer' (High performance, Low potential)\n",
            "Predictions: [2 2 6 2 2 4 2 2 2 2 5 4 2 2 2 2 2 2 5 2 1 2 2 2 1 5 2]\n",
            "Gold Values: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Ids: Int64Index([20013, 20012, 20011, 20097, 20139, 20095, 20220, 20221, 20222,\n",
            "            20223, 20224, 20096, 20178, 20180, 20138, 20181, 20140, 20182,\n",
            "            20137, 20136, 20052, 20053, 20014, 20054, 20179, 20055, 20056],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 19 / 27\n",
            "\n",
            "Class: Category 4: 'Inconsistent Player' (Low performance, Moderate potential)\n",
            "Predictions: [0 6 0 6 3 2 0 0 1 3 2 4 3 2 1 3 3 2 3 0 3 3 3 3 3 0]\n",
            "Gold Values: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
            "Ids: Int64Index([20143, 20144, 20102, 20101, 20100, 20099, 20098, 20142, 20141,\n",
            "            20225, 20015, 20227, 20228, 20017, 20016, 20145, 20057, 20058,\n",
            "            20059, 20060, 20061, 20185, 20184, 20183, 20226, 20186],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 11 / 26\n",
            "\n",
            "Class: Category 5: 'Core Player' (Moderate performance, Moderate potential)\n",
            "Predictions: [4 7 4 6 4 5 5 7 4 1 4 5 4 5 1 4 4 7 2 5 2 4 4 5 4 5 3 2 5 4]\n",
            "Gold Values: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
            "Ids: Int64Index([20147, 20148, 20229, 20191, 20190, 20187, 20188, 20230, 20231,\n",
            "            20149, 20150, 20189, 20146, 20233, 20065, 20107, 20104, 20103,\n",
            "            20066, 20064, 20063, 20062, 20106, 20105, 20232, 20022, 20021,\n",
            "            20020, 20019, 20018],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 12 / 30\n",
            "\n",
            "Class: Category 6: 'High Performer' (High performance, Moderate potential)\n",
            "Predictions: [5 5 7 5 5 6 5 8 5 5 5 6 2 2 8 8 5 5 5 5 2 8 2 2]\n",
            "Gold Values: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
            "Ids: Int64Index([20154, 20069, 20155, 20193, 20070, 20067, 20153, 20196, 20195,\n",
            "            20192, 20068, 20152, 20194, 20151, 20023, 20024, 20027, 20026,\n",
            "            20025, 20108, 20109, 20112, 20111, 20110],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 12 / 24\n",
            "\n",
            "Class: Category 7: 'Potential Gem' (Low performance, High potential)\n",
            "Predictions: [5 0 6 6 1 6 6 6 7 2 6 6 3 3 2 6 6 2 3 6 3 6]\n",
            "Gold Values: [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
            "Ids: Int64Index([20072, 20071, 20200, 20030, 20114, 20199, 20198, 20197, 20115,\n",
            "            20073, 20113, 20201, 20158, 20029, 20028, 20156, 20157, 20159,\n",
            "            20160, 20031, 20032, 20074],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 11 / 22\n",
            "\n",
            "Class: Category 8: 'High Potential' (Moderate performance, High potential)\n",
            "Predictions: [6 5 2 5 4 4 5 5 5 5 5 5 4 6 6 5 6 8 5 5 8 2 8 5 5]\n",
            "Gold Values: [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
            "Ids: Int64Index([20202, 20035, 20036, 20037, 20206, 20205, 20204, 20203, 20034,\n",
            "            20033, 20117, 20165, 20164, 20161, 20079, 20116, 20163, 20119,\n",
            "            20078, 20118, 20076, 20075, 20120, 20077, 20162],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 0 / 25\n",
            "\n",
            "Class: Category 9: 'Star' (High performance, High potential)\n",
            "Predictions: [8 6 8 8 8 5 8 5 5 8 8 8 4 8 5 8 8 8 5 8 5 5 5 8]\n",
            "Gold Values: [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
            "Ids: Int64Index([20084, 20083, 20082, 20081, 20080, 20121, 20125, 20124, 20039,\n",
            "            20166, 20167, 20211, 20210, 20209, 20208, 20207, 20168, 20169,\n",
            "            20122, 20042, 20041, 20040, 20038, 20123],\n",
            "           dtype='int64', name='id')\n",
            "Accuracy: 14 / 24\n",
            "\n",
            "Total Correct/Gold: 116/233\n",
            "\n",
            "AVG Accuracy: 0.4978540772532189\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHHI_6m8gqAm"
      },
      "source": [
        "#for data cleanup\n",
        "#_, train_predictions, true_train_vals = evaluate(dataloader_train, eval_model)\n",
        "#output_train_df = calculate_stats_per_class(train_predictions, true_train_vals, train_df)\n",
        "#output_train_df.to_csv('analysis/train_set_analysis.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v178083hOd1s"
      },
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
        "\n",
        "def confusion_matrix_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    unique_labels = np.unique(labels_flat)\n",
        "    return confusion_matrix(labels_flat, preds_flat, labels=unique_labels)\n",
        "\n",
        "\n",
        "cm = confusion_matrix_func(test_predictions, true_test_vals)\n",
        "\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "sn.heatmap(cm, annot=True, annot_kws={\"size\": 16},cmap=\"YlGnBu\") # font size\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ul7Ss2nIv3C"
      },
      "source": [
        "# Drawing the result Plot\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "from matplotlib.ticker import StrMethodFormatter\n",
        "\n",
        "lc_file_name = f'stats/learning_curve_{epochs}.csv';\n",
        "\n",
        "df_learning_curve = pd.read_csv(lc_file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bAq13kj-KXx"
      },
      "source": [
        "# Training loss plot\n",
        "\n",
        "plt.plot( 'epoch', 'train_loss_avg', data=df_learning_curve,   color='skyblue', linewidth=2, label=\"train_loss_avg\")\n",
        "plt.plot( 'epoch', 'validation_loss', data=df_learning_curve,  color='olive', linewidth=2, label=\"validation_loss\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.title('BERT Training Loss') \n",
        "plt.grid(True) \n",
        "#plt.ylim(0, 2.5)\n",
        "plt.gca().xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA0KZWADLW3C"
      },
      "source": [
        "# Training Evaluation Dynamics plot\n",
        "plt.plot( 'epoch', 'val_f1_weighted', data=df_learning_curve,  color='red', linewidth=2,  label=\"val_f1_weighted\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('score')\n",
        "plt.legend()\n",
        "plt.title('Model Evaluation Dynamics') \n",
        "plt.grid(True) \n",
        "plt.gca().xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
        "plt.ylim(0, 1)\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}